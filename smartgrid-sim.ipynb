{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xubd2IIGIr3D"
      },
      "source": [
        "smart grid simulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp1jQePBIr3E"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PeNnoIsTIr3E"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, Optional, List, Tuple, Literal\n",
        "from enum import Enum, auto\n",
        "from collections import deque\n",
        "import heapq\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "# silence future pandas groupby warning in our summaries (optional)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"pandas.core.groupby\")\n",
        "\n",
        "# reproducibility\n",
        "DEFAULT_SEED = 42\n",
        "rng = np.random.default_rng(DEFAULT_SEED)\n",
        "\n",
        "Time = float\n",
        "ID = int\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7KvrvlTZIr3F"
      },
      "outputs": [],
      "source": [
        "class PolicyType(Enum):\n",
        "    FIFO = auto()\n",
        "    NPPS = auto()   # Non-Preemptive Priority Scheduling\n",
        "    WRR  = auto()   # Weighted Round Robin\n",
        "    EDF  = auto()   # Earliest Deadline First\n",
        "\n",
        "@dataclass\n",
        "class SimConfig:\n",
        "    # --- non-defaults first ---\n",
        "    chi_arrival: float                   # χ — Poisson arrival rate\n",
        "    lambda_ctrl: float                   # λ1 — controller service rate (exp)\n",
        "    lambda_res: Dict[str, float]         # λ2 per resource {'PV':6, 'BAT':12, ...}\n",
        "    setup_delay: float                   # t — fixed setup delay (ctrl & res)\n",
        "    T: Time                              # total horizon\n",
        "    N_ctrl: int                          # number of controller servers (M/M/N)\n",
        "    transfer_overhead: Dict[str, float]  # C_time per resource (routing delay)\n",
        "    route_probs: Dict[str, float]        # P routing probabilities to resources\n",
        "\n",
        "    # --- defaults below ---\n",
        "    ctrl_policy: PolicyType = PolicyType.FIFO\n",
        "\n",
        "    # priorities & default deadlines (slots interpreted in same time unit)\n",
        "    group_priority: Dict[str, int] = field(\n",
        "        default_factory=lambda: {\"essential\": 3, \"delay_sensitive\": 2, \"delay_tolerant\": 1}\n",
        "    )\n",
        "    default_deadline_slots: Dict[str, Tuple[int,int]] = field(\n",
        "        default_factory=lambda: {\"delay_sensitive\": (1,4), \"delay_tolerant\": (3,12)}\n",
        "    )\n",
        "    seed: int = DEFAULT_SEED\n",
        "\n",
        "    def validate(self):\n",
        "        assert self.chi_arrival > 0, \"chi_arrival must be > 0\"\n",
        "        assert self.lambda_ctrl > 0, \"lambda_ctrl must be > 0\"\n",
        "        assert all(v > 0 for v in self.lambda_res.values()), \"All lambda_res must be > 0\"\n",
        "        assert self.N_ctrl >= 1, \"N_ctrl must be >= 1\"\n",
        "        assert self.T > 0, \"T must be > 0\"\n",
        "        s = sum(self.route_probs.values())\n",
        "        assert abs(s - 1.0) < 1e-8, f\"route_probs must sum to 1 (got {s})\"\n",
        "        # keys must align\n",
        "        for r in self.transfer_overhead:\n",
        "            assert r in self.lambda_res, f\"transfer_overhead key {r} missing in lambda_res\"\n",
        "        for r in self.lambda_res:\n",
        "            assert r in self.transfer_overhead, f\"lambda_res key {r} missing in transfer_overhead\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fB_Nl0JdIr3F"
      },
      "outputs": [],
      "source": [
        "from math import inf\n",
        "\n",
        "@dataclass\n",
        "class Request:\n",
        "    rid: ID\n",
        "    group: str                          # 'essential' | 'delay_sensitive' | 'delay_tolerant' | ...\n",
        "    priority: int                       # for NPPS\n",
        "    arrival_time: Time\n",
        "    deadline_time: Optional[Time] = None\n",
        "\n",
        "    # timestamps through system\n",
        "    t_ctrl_start: Optional[Time] = None\n",
        "    t_ctrl_end:   Optional[Time] = None\n",
        "    routed_to:    Optional[str]  = None\n",
        "    t_route_done: Optional[Time] = None\n",
        "    t_res_start:  Optional[Time] = None\n",
        "    t_res_end:    Optional[Time] = None\n",
        "\n",
        "class BaseQueuePolicy:\n",
        "    def push(self, req: Request) -> None: ...\n",
        "    def pop(self, now: Time) -> Optional[Request]: ...\n",
        "    def __len__(self) -> int: ...\n",
        "\n",
        "class FIFOQueue(BaseQueuePolicy):\n",
        "    def __init__(self): self._q = deque()\n",
        "    def push(self, req: Request) -> None: self._q.append(req)\n",
        "    def pop(self, now: Time) -> Optional[Request]:\n",
        "        return self._q.popleft() if self._q else None\n",
        "    def __len__(self) -> int: return len(self._q)\n",
        "\n",
        "class NPPSQueue(BaseQueuePolicy):\n",
        "    \"\"\"Higher priority first; FIFO within same priority.\"\"\"\n",
        "    def __init__(self):\n",
        "        self._counter = 0\n",
        "        self._heap: List[Tuple[int, int, Request]] = []  # (-priority, order, req)\n",
        "    def push(self, req: Request) -> None:\n",
        "        self._counter += 1\n",
        "        heapq.heappush(self._heap, (-int(req.priority), self._counter, req))\n",
        "    def pop(self, now: Time) -> Optional[Request]:\n",
        "        if not self._heap: return None\n",
        "        _, _, req = heapq.heappop(self._heap)\n",
        "        return req\n",
        "    def __len__(self) -> int: return len(self._heap)\n",
        "\n",
        "class EDFQueue(BaseQueuePolicy):\n",
        "    \"\"\"Earliest absolute deadline first; FIFO on ties; NaN/None treated as +inf.\"\"\"\n",
        "    def __init__(self):\n",
        "        self._counter = 0\n",
        "        self._heap: List[Tuple[float, int, Request]] = []  # (deadline, order, req)\n",
        "    def push(self, req: Request) -> None:\n",
        "        self._counter += 1\n",
        "        dl = req.deadline_time if (req.deadline_time is not None) else inf\n",
        "        heapq.heappush(self._heap, (float(dl), self._counter, req))\n",
        "    def pop(self, now: Time) -> Optional[Request]:\n",
        "        if not self._heap: return None\n",
        "        _, _, req = heapq.heappop(self._heap)\n",
        "        return req\n",
        "    def __len__(self) -> int: return len(self._heap)\n",
        "\n",
        "class WRRQueue(BaseQueuePolicy):\n",
        "    \"\"\"\n",
        "    Weighted Round Robin over groups (each group has FIFO).\n",
        "    Weights are positive numbers; internally normalized to small integers.\n",
        "    \"\"\"\n",
        "    def __init__(self, group_weights: Dict[str, float]):\n",
        "        assert all(w > 0 for w in group_weights.values()), \"WRR weights must be > 0\"\n",
        "        self.fifos: Dict[str, deque] = {g: deque() for g in group_weights}\n",
        "        # normalize to small integers for quotas\n",
        "        g, w = zip(*group_weights.items())\n",
        "        base = min(w)\n",
        "        ints = {gi: max(1, int(round(wi / base))) for gi, wi in group_weights.items()}\n",
        "        self.weights = ints\n",
        "        self.groups = list(self.fifos.keys())\n",
        "        self.idx = 0\n",
        "        self.quota_left = dict(self.weights)\n",
        "\n",
        "    def push(self, req: Request) -> None:\n",
        "        if req.group not in self.fifos:\n",
        "            # unseen group gets weight 1 lazily\n",
        "            self.fifos[req.group] = deque()\n",
        "            self.weights[req.group] = 1\n",
        "            self.groups.append(req.group)\n",
        "            self.quota_left[req.group] = 1\n",
        "        self.fifos[req.group].append(req)\n",
        "\n",
        "    def _advance(self): self.idx = (self.idx + 1) % len(self.groups)\n",
        "    def _has_any(self) -> bool: return any(self.fifos[g] for g in self.groups)\n",
        "\n",
        "    def pop(self, now: Time) -> Optional[Request]:\n",
        "        if not self._has_any(): return None\n",
        "        tried = 0\n",
        "        while tried < len(self.groups):\n",
        "            g = self.groups[self.idx]\n",
        "            # reset cycle quotas if all exhausted\n",
        "            if all(self.quota_left[x] == 0 for x in self.groups):\n",
        "                self.quota_left = dict(self.weights)\n",
        "            if self.quota_left[g] == 0 or not self.fifos[g]:\n",
        "                self._advance(); tried += 1; continue\n",
        "            self.quota_left[g] -= 1\n",
        "            return self.fifos[g].popleft()\n",
        "        # queues changed; reset quotas and retry once\n",
        "        self.quota_left = dict(self.weights)\n",
        "        return self.pop(now)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MJJEu99LIr3F"
      },
      "outputs": [],
      "source": [
        "def make_queue(policy: PolicyType, *, wrr_weights: Optional[Dict[str, float]] = None) -> BaseQueuePolicy:\n",
        "    if policy == PolicyType.FIFO: return FIFOQueue()\n",
        "    if policy == PolicyType.NPPS: return NPPSQueue()\n",
        "    if policy == PolicyType.EDF:  return EDFQueue()\n",
        "    if policy == PolicyType.WRR:\n",
        "        assert wrr_weights is not None and len(wrr_weights) > 0, \"Provide wrr_weights for WRR\"\n",
        "        return WRRQueue(wrr_weights)\n",
        "    raise NotImplementedError(policy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "voZQKtLCIr3G"
      },
      "outputs": [],
      "source": [
        "class EventType(Enum):\n",
        "    ARRIVAL = auto()       # to controller\n",
        "    CTRL_FINISH = auto()   # controller finished a request\n",
        "    RES_ARRIVAL = auto()   # arrival to a resource after transfer overhead\n",
        "    RES_FINISH = auto()    # resource finished\n",
        "\n",
        "@dataclass(order=True)\n",
        "class Event:\n",
        "    time: Time\n",
        "    etype: EventType\n",
        "    payload: dict = field(compare=False)\n",
        "\n",
        "class ResourceServer:\n",
        "    \"\"\"Single-server M/M/1 resource with FIFO queue (per resource).\"\"\"\n",
        "    def __init__(self, name: str, rate: float, setup_delay: float):\n",
        "        self.name = name\n",
        "        self.rate = rate\n",
        "        self.setup_delay = setup_delay\n",
        "        self.queue = deque()\n",
        "        self.busy_until: Time = 0.0\n",
        "        self.in_service: Optional[Request] = None\n",
        "\n",
        "    def push(self, req: Request):\n",
        "        self.queue.append(req)\n",
        "\n",
        "    def try_start(self, now: Time, evq: List[Event]):\n",
        "        if self.in_service is not None: return False\n",
        "        if self.queue and self.busy_until <= now:\n",
        "            req = self.queue.popleft()\n",
        "            req.t_res_start = now\n",
        "            svc = rng.exponential(1.0 / self.rate) + self.setup_delay\n",
        "            finish = now + svc\n",
        "            self.busy_until = finish\n",
        "            self.in_service = req\n",
        "            heapq.heappush(evq, Event(finish, EventType.RES_FINISH, {\"res\": self.name, \"req\": req}))\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def on_finish(self, now: Time):\n",
        "        req = self.in_service\n",
        "        if req: req.t_res_end = now\n",
        "        self.in_service = None\n",
        "        self.busy_until = now\n",
        "\n",
        "class ResourcePool:\n",
        "    def __init__(self, cfg: SimConfig):\n",
        "        self.cfg = cfg\n",
        "        self.resources: Dict[str, ResourceServer] = {\n",
        "            rname: ResourceServer(rname, rate=lambda_rate, setup_delay=cfg.setup_delay)\n",
        "            for rname, lambda_rate in cfg.lambda_res.items()\n",
        "        }\n",
        "\n",
        "    def route_choice(self) -> str:\n",
        "        names = list(self.cfg.route_probs.keys())\n",
        "        probs = np.array(list(self.cfg.route_probs.values()))\n",
        "        return rng.choice(names, p=probs)\n",
        "\n",
        "    def on_ctrl_finish(self, req: Request, now: Time, evq: List[Event]):\n",
        "        rname = self.route_choice()\n",
        "        req.routed_to = rname\n",
        "        req.t_ctrl_end = now\n",
        "        overhead = self.cfg.transfer_overhead.get(rname, 0.0)\n",
        "        arrival_at_res = now + overhead\n",
        "        req.t_route_done = arrival_at_res\n",
        "        heapq.heappush(evq, Event(arrival_at_res, EventType.RES_ARRIVAL, {\"res\": rname, \"req\": req}))\n",
        "\n",
        "    def on_res_arrival(self, rname: str, req: Request, now: Time, evq: List[Event]):\n",
        "        res = self.resources[rname]\n",
        "        res.push(req)\n",
        "        res.try_start(now, evq)\n",
        "\n",
        "    def on_res_finish(self, rname: str, now: Time, evq: List[Event]):\n",
        "        res = self.resources[rname]\n",
        "        res.on_finish(now)\n",
        "        res.try_start(now, evq)\n",
        "\n",
        "class MultiServerController:\n",
        "    \"\"\"Controller M/M/N with pluggable queue.\"\"\"\n",
        "    def __init__(self, cfg: SimConfig):\n",
        "        self.cfg = cfg\n",
        "        if cfg.ctrl_policy == PolicyType.WRR:\n",
        "            # by default map weights from priorities (custom dict welcome too)\n",
        "            wrr_weights = {g: float(p) for g, p in cfg.group_priority.items()}\n",
        "            self.queue = make_queue(cfg.ctrl_policy, wrr_weights=wrr_weights)\n",
        "        else:\n",
        "            self.queue = make_queue(cfg.ctrl_policy)\n",
        "        self.server_busy_until: List[Time] = [0.0] * cfg.N_ctrl\n",
        "        self.in_service: Dict[int, Request] = {}\n",
        "\n",
        "    def _first_free_server(self, now: Time) -> Optional[int]:\n",
        "        for sid, busy_until in enumerate(self.server_busy_until):\n",
        "            if busy_until <= now and self.in_service.get(sid) is None:\n",
        "                return sid\n",
        "        return None\n",
        "\n",
        "    def try_start_service(self, now: Time, evq: List[Event]):\n",
        "        started = 0\n",
        "        while True:\n",
        "            sid = self._first_free_server(now)\n",
        "            if sid is None: break\n",
        "            req = self.queue.pop(now)\n",
        "            if req is None: break\n",
        "            req.t_ctrl_start = now\n",
        "            svc = rng.exponential(1.0 / self.cfg.lambda_ctrl) + self.cfg.setup_delay\n",
        "            finish = now + svc\n",
        "            self.server_busy_until[sid] = finish\n",
        "            self.in_service[sid] = req\n",
        "            heapq.heappush(evq, Event(finish, EventType.CTRL_FINISH, {\"sid\": sid, \"req\": req}))\n",
        "            started += 1\n",
        "        return started\n",
        "\n",
        "    def on_arrival(self, req: Request, now: Time, evq: List[Event]):\n",
        "        self.queue.push(req)\n",
        "        self.try_start_service(now, evq)\n",
        "\n",
        "    def on_finish(self, sid: int, now: Time) -> Request:\n",
        "        self.server_busy_until[sid] = now\n",
        "        return self.in_service.pop(sid)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YQsgiEPSIr3G"
      },
      "outputs": [],
      "source": [
        "def generate_next_arrival(prev_time: Time, chi: float) -> Time:\n",
        "    return prev_time + rng.exponential(1.0 / chi)\n",
        "\n",
        "def _sample_deadline_for_group(cfg: SimConfig, group: str, arrival_time: float) -> Optional[float]:\n",
        "    if group in cfg.default_deadline_slots:\n",
        "        lo, hi = cfg.default_deadline_slots[group]\n",
        "        delta = float(rng.uniform(lo, hi))\n",
        "        return arrival_time + delta\n",
        "    return None\n",
        "\n",
        "def bootstrap_requests(cfg: SimConfig, group_mix: Dict[str, float]) -> List[Request]:\n",
        "    assert abs(sum(group_mix.values()) - 1.0) < 1e-8, \"group_mix must sum to 1\"\n",
        "    t = 0.0\n",
        "    rid = 0\n",
        "    reqs: List[Request] = []\n",
        "    groups = list(group_mix.keys())\n",
        "    probs  = np.array(list(group_mix.values()))\n",
        "    while t < cfg.T:\n",
        "        t = generate_next_arrival(t, cfg.chi_arrival)\n",
        "        if t >= cfg.T: break\n",
        "        g = rng.choice(groups, p=probs)\n",
        "        pr = cfg.group_priority.get(g, 1)\n",
        "        dl = _sample_deadline_for_group(cfg, g, t)\n",
        "        reqs.append(Request(\n",
        "            rid=rid, group=g, priority=pr,\n",
        "            arrival_time=t, deadline_time=dl\n",
        "        ))\n",
        "        rid += 1\n",
        "    return reqs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "77_80BPpIr3G"
      },
      "outputs": [],
      "source": [
        "def generate_next_arrival(prev_time: Time, chi: float) -> Time:\n",
        "    return prev_time + rng.exponential(1.0 / chi)\n",
        "\n",
        "def _sample_deadline_for_group(cfg: SimConfig, group: str, arrival_time: float) -> Optional[float]:\n",
        "    if group in cfg.default_deadline_slots:\n",
        "        lo, hi = cfg.default_deadline_slots[group]\n",
        "        delta = float(rng.uniform(lo, hi))\n",
        "        return arrival_time + delta\n",
        "    return None\n",
        "\n",
        "def bootstrap_requests(cfg: SimConfig, group_mix: Dict[str, float]) -> List[Request]:\n",
        "    assert abs(sum(group_mix.values()) - 1.0) < 1e-8, \"group_mix must sum to 1\"\n",
        "    t = 0.0\n",
        "    rid = 0\n",
        "    reqs: List[Request] = []\n",
        "    groups = list(group_mix.keys())\n",
        "    probs  = np.array(list(group_mix.values()))\n",
        "    while t < cfg.T:\n",
        "        t = generate_next_arrival(t, cfg.chi_arrival)\n",
        "        if t >= cfg.T: break\n",
        "        g = rng.choice(groups, p=probs)\n",
        "        pr = cfg.group_priority.get(g, 1)\n",
        "        dl = _sample_deadline_for_group(cfg, g, t)\n",
        "        reqs.append(Request(\n",
        "            rid=rid, group=g, priority=pr,\n",
        "            arrival_time=t, deadline_time=dl\n",
        "        ))\n",
        "        rid += 1\n",
        "    return reqs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HYxXA-XZIr3G"
      },
      "outputs": [],
      "source": [
        "def summarize_metrics(df: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Returns (overall_df, per_group_df, miss_df or None)\n",
        "    overall/per_group: count/valid, mean, median, p95 for core timing columns.\n",
        "    miss_df: per-group deadline meeting/miss stats (+ __OVERALL__), if 'deadline' present.\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        return pd.DataFrame(), pd.DataFrame(), None\n",
        "\n",
        "    cols = [\"wait_ctrl\", \"svc_ctrl\", \"transfer\", \"wait_res\", \"svc_res\", \"total_response\"]\n",
        "\n",
        "    overall = df[cols].agg([\"count\", \"mean\", \"median\", lambda s: s.quantile(0.95)]).T\n",
        "    overall.columns = [\"count/valid\", \"mean\", \"median\", \"p95\"]\n",
        "    overall = overall.sort_index()\n",
        "\n",
        "    # exclude grouping col from apply to avoid future behavior change\n",
        "    per_group = df.groupby(\"group\", dropna=False)[cols].apply(\n",
        "        lambda g: g.agg([\"count\", \"mean\", \"median\", lambda s: s.quantile(0.95)]).T\n",
        "    )\n",
        "    per_group.columns = [\"count/valid\", \"mean\", \"median\", \"p95\"]\n",
        "\n",
        "    # deadline miss table\n",
        "    miss_table = None\n",
        "    if \"deadline\" in df.columns:\n",
        "        m = df.dropna(subset=[\"deadline\"]).copy()\n",
        "        if not m.empty:\n",
        "            m[\"deadline_met\"] = (m[\"res_end\"] <= m[\"deadline\"]).astype(int)\n",
        "            g = m.groupby(\"group\", dropna=False)[\"deadline_met\"].agg(count=\"count\", met=\"sum\")\n",
        "            g[\"misses\"] = g[\"count\"] - g[\"met\"]\n",
        "            g[\"miss_rate\"] = g[\"misses\"] / g[\"count\"]\n",
        "            overall_miss = pd.DataFrame({\n",
        "                \"count\": [g[\"count\"].sum()],\n",
        "                \"met\": [g[\"met\"].sum()],\n",
        "                \"misses\": [g[\"misses\"].sum()],\n",
        "                \"miss_rate\": [g[\"misses\"].sum() / max(1, g[\"count\"].sum())]\n",
        "            }, index=[\"__OVERALL__\"])\n",
        "            miss_table = pd.concat([g, overall_miss])\n",
        "\n",
        "    return overall, per_group, miss_table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vh-F16dzIr3H"
      },
      "outputs": [],
      "source": [
        "def run_simulation(cfg: SimConfig, group_mix: Dict[str, float]) -> pd.DataFrame:\n",
        "    cfg.validate()\n",
        "    # reset RNG per run\n",
        "    global rng\n",
        "    rng = np.random.default_rng(cfg.seed)\n",
        "\n",
        "    reqs = bootstrap_requests(cfg, group_mix)\n",
        "    controller = MultiServerController(cfg)\n",
        "    pool = ResourcePool(cfg)\n",
        "\n",
        "    # prime event queue with arrivals\n",
        "    evq: List[Event] = []\n",
        "    for req in reqs:\n",
        "        heapq.heappush(evq, Event(req.arrival_time, EventType.ARRIVAL, {\"req\": req}))\n",
        "\n",
        "    # main loop\n",
        "    while evq:\n",
        "        ev = heapq.heappop(evq)\n",
        "        now = ev.time\n",
        "        if now > cfg.T: break\n",
        "\n",
        "        if ev.etype == EventType.ARRIVAL:\n",
        "            controller.on_arrival(ev.payload[\"req\"], now, evq)\n",
        "\n",
        "        elif ev.etype == EventType.CTRL_FINISH:\n",
        "            sid = ev.payload[\"sid\"]\n",
        "            req: Request = controller.on_finish(sid, now)\n",
        "            pool.on_ctrl_finish(req, now, evq)\n",
        "            controller.try_start_service(now, evq)\n",
        "\n",
        "        elif ev.etype == EventType.RES_ARRIVAL:\n",
        "            rname = ev.payload[\"res\"]\n",
        "            req: Request = ev.payload[\"req\"]\n",
        "            pool.on_res_arrival(rname, req, now, evq)\n",
        "\n",
        "        elif ev.etype == EventType.RES_FINISH:\n",
        "            rname = ev.payload[\"res\"]\n",
        "            pool.on_res_finish(rname, now, evq)\n",
        "\n",
        "    # assemble results\n",
        "    finished: List[Request] = [r for r in reqs if r.t_res_end is not None]\n",
        "\n",
        "    def safe(x): return None if x is None else float(x)\n",
        "\n",
        "    rows = []\n",
        "    for r in finished:\n",
        "        wait_ctrl = (r.t_ctrl_start - r.arrival_time) if (r.t_ctrl_start is not None) else None\n",
        "        svc_ctrl  = (r.t_ctrl_end - r.t_ctrl_start) if (r.t_ctrl_end is not None and r.t_ctrl_start is not None) else None\n",
        "        transfer  = (r.t_route_done - r.t_ctrl_end) if (r.t_route_done is not None and r.t_ctrl_end is not None) else None\n",
        "        wait_res  = (r.t_res_start - r.t_route_done) if (r.t_res_start is not None and r.t_route_done is not None) else None\n",
        "        svc_res   = (r.t_res_end - r.t_res_start) if (r.t_res_end is not None and r.t_res_start is not None) else None\n",
        "        total     = (r.t_res_end - r.arrival_time) if (r.t_res_end is not None) else None\n",
        "\n",
        "        rows.append({\n",
        "            \"rid\": r.rid,\n",
        "            \"group\": r.group,\n",
        "            \"priority\": r.priority,\n",
        "            \"arrival\": safe(r.arrival_time),\n",
        "            \"deadline\": safe(r.deadline_time),\n",
        "            \"ctrl_start\": safe(r.t_ctrl_start),\n",
        "            \"ctrl_end\": safe(r.t_ctrl_end),\n",
        "            \"routed_to\": r.routed_to,\n",
        "            \"route_done\": safe(r.t_route_done),\n",
        "            \"res_start\": safe(r.t_res_start),\n",
        "            \"res_end\": safe(r.t_res_end),\n",
        "            \"wait_ctrl\": safe(wait_ctrl),\n",
        "            \"svc_ctrl\": safe(svc_ctrl),\n",
        "            \"transfer\": safe(transfer),\n",
        "            \"wait_res\": safe(wait_res),\n",
        "            \"svc_res\": safe(svc_res),\n",
        "            \"total_response\": safe(total),\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(rows)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "o5TfvKShIr3H"
      },
      "outputs": [],
      "source": [
        "def run_policy_sweep(cfg_base: SimConfig, group_mix: Dict[str, float],\n",
        "                     policies: List[PolicyType]) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Runs multiple controller policies on the same base config (cloned per run)\n",
        "    and returns a compact summary table.\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for pol in policies:\n",
        "        cfg = SimConfig(\n",
        "            chi_arrival=cfg_base.chi_arrival,\n",
        "            lambda_ctrl=cfg_base.lambda_ctrl,\n",
        "            lambda_res=dict(cfg_base.lambda_res),\n",
        "            setup_delay=cfg_base.setup_delay,\n",
        "            T=cfg_base.T,\n",
        "            N_ctrl=cfg_base.N_ctrl,\n",
        "            transfer_overhead=dict(cfg_base.transfer_overhead),\n",
        "            route_probs=dict(cfg_base.route_probs),\n",
        "            ctrl_policy=pol,\n",
        "            group_priority=dict(cfg_base.group_priority),\n",
        "            default_deadline_slots=dict(cfg_base.default_deadline_slots),\n",
        "            seed=cfg_base.seed\n",
        "        )\n",
        "        df = run_simulation(cfg, group_mix)\n",
        "        overall, per_group, miss = summarize_metrics(df)\n",
        "\n",
        "        row = {\n",
        "            \"policy\": pol.name,\n",
        "            \"count\": overall.loc[\"total_response\", \"count/valid\"],\n",
        "            \"total_mean\": overall.loc[\"total_response\", \"mean\"],\n",
        "            \"total_p95\": overall.loc[\"total_response\", \"p95\"],\n",
        "            \"wait_ctrl_mean\": overall.loc[\"wait_ctrl\", \"mean\"],\n",
        "            \"wait_res_mean\": overall.loc[\"wait_res\", \"mean\"],\n",
        "            \"svc_ctrl_mean\": overall.loc[\"svc_ctrl\", \"mean\"],\n",
        "            \"svc_res_mean\": overall.loc[\"svc_res\", \"mean\"],\n",
        "            \"transfer_mean\": overall.loc[\"transfer\", \"mean\"],\n",
        "            \"deadline_miss_rate\": np.nan\n",
        "        }\n",
        "        if miss is not None and \"__OVERALL__\" in miss.index:\n",
        "            row[\"deadline_miss_rate\"] = float(miss.loc[\"__OVERALL__\", \"miss_rate\"])\n",
        "\n",
        "        rows.append(row)\n",
        "\n",
        "    return pd.DataFrame(rows).sort_values(by=[\"total_mean\", \"total_p95\"]).reset_index(drop=True)\n",
        "\n",
        "def with_load(cfg: SimConfig, chi_new: float, seed: Optional[int] = None) -> SimConfig:\n",
        "    return SimConfig(\n",
        "        chi_arrival=chi_new,\n",
        "        lambda_ctrl=cfg.lambda_ctrl,\n",
        "        lambda_res=dict(cfg.lambda_res),\n",
        "        setup_delay=cfg.setup_delay,\n",
        "        T=cfg.T,\n",
        "        N_ctrl=cfg.N_ctrl,\n",
        "        transfer_overhead=dict(cfg.transfer_overhead),\n",
        "        route_probs=dict(cfg.route_probs),\n",
        "        ctrl_policy=cfg.ctrl_policy,\n",
        "        group_priority=dict(cfg.group_priority),\n",
        "        default_deadline_slots=dict(cfg.default_deadline_slots),\n",
        "        seed=cfg.seed if seed is None else seed\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4LTXXC_HIr3H",
        "outputId": "ba429aa1-12e8-46d8-9e2d-066022bfa13d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'utilization_report' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3371651985.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_mix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0moverall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmiss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarize_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mrep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutilization_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mdash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline_dashboard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'utilization_report' is not defined"
          ]
        }
      ],
      "source": [
        "# # example usage\n",
        "cfg = SimConfig(\n",
        "    chi_arrival=8.0,\n",
        "    # lambda_ctrl=10.0,\n",
        "    # lambda_ctrl=6.0,\n",
        "    lambda_ctrl=6.0,\n",
        "    lambda_res={\"PV\":6.0, \"BAT\":12.0, \"GRID\":20.0},\n",
        "    # setup_delay=0.02,\n",
        "    setup_delay=0.05,\n",
        "    T=240.0,\n",
        "    # N_ctrl=2,\n",
        "    N_ctrl=2,\n",
        "    transfer_overhead={\"PV\":0.03, \"BAT\":0.02, \"GRID\":0.01},\n",
        "    route_probs={\"PV\":0.35, \"BAT\":0.25, \"GRID\":0.40},\n",
        "    ctrl_policy=PolicyType.FIFO,\n",
        ")\n",
        "group_mix = {\"essential\":0.2, \"delay_sensitive\":0.4, \"delay_tolerant\":0.4}\n",
        "\n",
        "df = run_simulation(cfg, group_mix)\n",
        "overall, per_group, miss = summarize_metrics(df)\n",
        "rep = utilization_report(cfg, df)\n",
        "dash = deadline_dashboard(df)\n",
        "\n",
        "display(df.head(), overall, per_group, miss, rep, dash)\n",
        "\n",
        "# try NPPS / EDF / WRR\n",
        "table = run_policy_sweep(cfg, group_mix, [PolicyType.FIFO, PolicyType.NPPS, PolicyType.WRR, PolicyType.EDF])\n",
        "display(table)\n",
        "\n",
        "# stress\n",
        "sweep_light = run_policy_sweep(with_load(cfg, 6.0), group_mix, [PolicyType.FIFO, PolicyType.NPPS, PolicyType.WRR, PolicyType.EDF])\n",
        "sweep_heavy = run_policy_sweep(with_load(cfg, 12.0), group_mix, [PolicyType.FIFO, PolicyType.NPPS, PolicyType.WRR, PolicyType.EDF])\n",
        "display(sweep_light, sweep_heavy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDhQiEOlIr3I"
      },
      "outputs": [],
      "source": [
        "# Next steps\n",
        "\n",
        "# Resource-side scheduling (carry priority/deadlines into PV/BAT/GRID): add res_policy (FIFO/NPPS/EDF/WRR) so differences show up in wait_res under PV stress.\n",
        "\n",
        "# Outage scenarios: inject on/off events for sources; measure impact on delays & miss rate.\n",
        "\n",
        "# (then) Hybrid selector and ML tasks (forecasting & clustering) atop the stable baseline."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}